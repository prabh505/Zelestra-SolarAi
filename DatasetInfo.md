## ğŸ“Š Dataset Description

The dataset used for **Phase 1: Solar PV Efficiency Prediction** consists of two files:

### ğŸ”¹ `train.csv`
Contains historical solar plant data used for training the machine learning model.  
Each row represents a time-stamped measurement of plant/system performance along with environmental conditions.

**Key columns (indicative):**
- `id` â€” Unique record identifier
- `efficiency` â€” Target variable: measured solar PV efficiency
- `temperature` â€” Temperature at the panel/inverter location
- `irradiance` â€” Solar irradiance level
- `humidity` â€” Ambient humidity
- `string_id` â€” Categorical string identifier for sub-system (encoded)
- `error_code` â€” Categorical error/event code from system sensors
- `installation_type` â€” Categorical type of installation
- *(Other engineered/system metrics)*

### ğŸ”¹ `test.csv`
Contains similar features as `train.csv` but **without the target `efficiency` column**.  
This data is used for generating predictions.

---

### âš  Note
> The dataset was provided by **Zelestra x AWS ML Ascend Challenge** organizers for competition use only.  
> We **do not redistribute the dataset** here â€” it must be obtained from the official source.

---

## ğŸ“‚ Phase1 Folder Contents

```text
Phase1/
â”œâ”€â”€ train.csv           # Solar plant training data (local copy for dev only)
â”œâ”€â”€ test.csv            # Test data for predictions (local copy for dev only)
â”œâ”€â”€ phase1_model.ipynb  # Notebook with full ML pipeline (feature engg, modeling, stacking)
â”œâ”€â”€ submission.csv      # Example output predictions file
â”œâ”€â”€ DATASET_INFO.md     # This dataset description and folder overview

---

## ğŸ“ Usage

Our code reads the dataset as:
```python
train = pd.read_csv("Phase1/train.csv")
test = pd.read_csv("Phase1/test.csv")

---
